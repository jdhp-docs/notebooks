{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "draft"
    ]
   },
   "source": [
    "# Minimisation du $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "Chi-squared test\n",
    "\n",
    "To see:\n",
    "- http://hamelg.blogspot.fr/2015/11/python-for-data-analysis-part-25-chi.html\n",
    "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.chisquare.html\n",
    "- https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.stats.chisquare.html\n",
    "- https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.stats.chi2.html\n",
    "\n",
    "- https://stats.stackexchange.com/questions/202617/implementing-chi-square-in-python-and-testing-on-scipys-poisson-and-norm-variat\n",
    "- https://python4mpia.github.io/fitting_data/least-squares-fitting.html\n",
    "- http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx2/notebooks/tableau_contingence.html\n",
    "- http://astropython.blogspot.fr/2012/02/computing-chi-squared-and-reduced-chi.html\n",
    "- http://connor-johnson.com/2014/12/31/the-pearson-chi-squared-test-with-python-and-r/\n",
    "- http://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "- http://glowingpython.blogspot.fr/2014/02/terms-selection-with-chi-square.html\n",
    "\n",
    "- https://stackoverflow.com/questions/22177576/python-minimizing-chi-squared\n",
    "- https://stackoverflow.com/questions/39486270/scipy-optimize-minimize-chi-squared-python\n",
    "- https://stats.stackexchange.com/questions/139108/optimizing-parameter-estimates-by-minimizing-chi2-in-iterative-procedure\n",
    "- https://lmfit.github.io/lmfit-py/fitting.html\n",
    "- https://www.youtube.com/watch?v=Awv_DqwEIxY\n",
    "\n",
    "TODO:\n",
    "- examples on how to minimize chi-squared to find distribution parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problèmatique:\n",
    "On suppose qu'on a un *échantillon* et que la *loi de probabilité* $L_{v}$ qui à généré cet échantillon est inconnue.\n",
    "Comment retrouver cette loi et ses paramètres à partir de l'échantillon dont on dispose ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- À partir de l'*échantillon*, on peut calculer une *loi de probabilité empirique* $L_e$ (\"e\" pour empirique) ayant une *fonction de répartition* $F_e$.\n",
    "- À partir de cette loi empirique (et d'éventuelles autres informations sur $L_v$), on choisi parmi les lois usuelles celles qui lui ressemble le plus.\n",
    "- Supposons qu'on choisi une certaine loi $L_h$ (\"h\" pour hypothèse) de fonction de répartition $F_h$.\n",
    "- On pourra valider ce choix si la distance $d(F_h, F_e)$ entre les fonctions de répartition $F_h$ et $F_e$ est faible, i.e. si $d(F_h, F_e) \\lt C$.\n",
    "- On pourrait cependant se tromper en rejetant notre choix alors qu'il est bien correct. Cette erreur se produit avec une probabilité qui est $P_{err} = P \\left\\{ d(F_h, F_e) \\gt C \\right\\}$.\n",
    "- Si on veut que le risque d'erreur soit faible, on peut fixer $P_{err}$ (par exemple $P_{err} \\lt 0.1$ (**TODO: \"=\"**) pour un risque inférieur à (**TODO: \"égale à\"**) 1%).\n",
    "- Le choix de $P_{err}$ nous permet de déterminer la valeur de la constante $C$ à utiliser ($C$ est appellée *seuil d'acceptation* ou *seuil critique*).\n",
    "- **TODO...**\n",
    "- On réalise ainsi un test d'adéquation (ou d'ajustement) entre une *loi théorique* donnée (ici définie par $F_h$) et une *loi empirique* issue d'un échantillon observé.\n",
    "- Ok, reste à définir cette distance $d$, i.e. le test utilisé\n",
    "    - pour les lois discrètes (**TODO: \"si $L_h$ est discrète\"**), on utilise le *test du chi-deux* ($\\chi^2$)\n",
    "    - pour les lois continues, on utilise plutôt le *test de Kolmogorov-Smirnov*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d(F_h, F_e) = \\sum^{k}_{i=1}\\frac{(n_{ei} - n_{hi})^2}{n_{hi}}$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $n_{ei}$ est l'effectif observé de $x_i$ (le nombre d'observation  de $x_i$)\n",
    "- $n_{hi}$ est l'effectif théorique de $x_i$ avec $n_{hi} = np_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple pour un échantillon de 100 tirages à pile ou face\n",
    "\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "x_i    & \\text{pile} & \\text{face} \\\\\n",
    "\\hline\n",
    "n_{ei} & 47 & 53 \\\\\n",
    "n_{hi} & 50 & 50 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "| $x_i$    | pile | face |\n",
    "| -------- | ---- | ---- |\n",
    "| $n_{ei}$ | 47   | 53   |\n",
    "| $n_{hi}$ | 50   | 50   |\n",
    "\n",
    "$$d(F_h, F_e) = \\frac{(47 - 50)^2}{50} + \\frac{(53 - 50)^2}{50} = 0.36$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la loi de probablité supposée inconnue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La loi de probabilité à retrouver est une loi binomiale $\\mathcal{b}(100, 0.25)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "data = np.random.binomial(n=n, p=p, size=100000)\n",
    "plt.hist(data,\n",
    "         bins=np.linspace(data.min(), data.max(), data.max() - data.min() + 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E(X) = np = 25$\n",
    "\n",
    "$V(X) = np(1-p) = 18.75$\n",
    "\n",
    "$STD(X) = \\sqrt{18.75} \\simeq 4.33$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de l'échantillon disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 100   # taille de l'echantillon\n",
    "echantillon = np.random.binomial(n=n, p=p, size=k)\n",
    "#np.random.normal(loc=m, scale=sigma, size=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution empirique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(echantillon,\n",
    "         bins=np.linspace(echantillon.min(), echantillon.max(), echantillon.max() - echantillon.min() + 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(echantillon,\n",
    "         bins=np.linspace(echantillon.min(), echantillon.max(), echantillon.max() - echantillon.min() + 1),\n",
    "         cumulative=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"moyenne:\", m)\n",
    "#print(\"écart type:\", sigma)\n",
    "\n",
    "print(\"moyenne empirique de l'échantillon:\", echantillon.mean())\n",
    "print(\"écart type empirique de l'échantillon:\", echantillon.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition et test des hypothèses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_chi2(x, *param):\n",
    "    n = x[0]\n",
    "    p = x[1]\n",
    "    \n",
    "    dist = 0\n",
    "    \n",
    "    n_xi = 10 # TODO\n",
    "    \n",
    "    for xi in range(n_xi):\n",
    "        n_ei = 0   # TODO\n",
    "        n_hi = 0   # TODO\n",
    "        \n",
    "        dist += ((n_ei - n_hi)**2) / n_hi\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "n_slice = slice(1., 200., 1.)\n",
    "p_slice = slice(0.1, 1.0, 0.1)\n",
    "\n",
    "search_ranges = (n_slice, p_slice)\n",
    "\n",
    "#res = optimize.brute(dist_chi2,\n",
    "#                     search_ranges,\n",
    "#                     #args=params,\n",
    "#                     full_output=True,\n",
    "#                     finish=optimize.fmin)\n",
    "\n",
    "#print(\"x* =\", res[0])\n",
    "#print(\"f(x*) =\", res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "- *Statistique et Pobabilités* de Jean-Pierre Lecoutre, 2006 Dunod, 3e édition p.154"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
