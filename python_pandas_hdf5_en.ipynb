{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "meta",
     "draft"
    ]
   },
   "source": [
    "# HDF5 files with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "**TODO**\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# import python packages here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:\n",
    "* https://pandas.pydata.org/pandas-docs/stable/io.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook-hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"test.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm test.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read/write HDF files using `HDFStore` objects API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HDFStore` is a dict-like object which reads and writes pandas using the high performance HDF5 format using the PyTables library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/io.html#hdf5-pytables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data to save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([3.14, 2.72, np.nan], index=['pi', 'e', 'nan'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[3, 1, 4],[2, 7, np.nan]]).T,\n",
    "                  index=pd.date_range('1/1/2000', periods=3),\n",
    "                  columns=['A', 'B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects can be written to the file just like adding key-value pairs to a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['df'] = df      # the equivalent of: store.put('df', df)\n",
    "store['series'] = s   # the equivalent of: store.put('series', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing a Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del s\n",
    "del store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(FILE) as store:\n",
    "    print(store.keys())\n",
    "    df = store['df']      # the equivalent of: store.get('df')\n",
    "    s = store['series']   # the equivalent of: store.get('series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read/Write HDF5 files using the `to_hdf()`/`read_hdf()` top-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HDFStore` supports an top-level API using `read_hdf` for reading and `to_hdf` for writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/io.html#id2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data to save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm test.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([3.14, 2.72, np.nan], index=['pi', 'e', 'nan'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[3, 1, 4],[2, 7, np.nan]]).T,\n",
    "                  index=pd.date_range('1/1/2000', periods=3),\n",
    "                  columns=['A', 'B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a DataFrame in a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_hdf(FILE, key='series')\n",
    "df.to_hdf(FILE, key='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful paremeters:\n",
    "\n",
    "    format : 'fixed(f)|table(t)', default is 'fixed'\n",
    "        fixed(f) : Fixed format\n",
    "                   Fast writing/reading. Not-appendable, nor searchable\n",
    "        table(t) : Table format\n",
    "                   Write as a PyTables Table structure which may perform\n",
    "                   worse but allow more flexible operations like searching\n",
    "                   / selecting subsets of the data\n",
    "    append : boolean, default False\n",
    "        For Table formats, append the input data to the existing\n",
    "    data_columns :  list of columns, or True, default None\n",
    "        List of columns to create as indexed data columns for on-disk\n",
    "        queries, or True to use all columns. By default only the axes\n",
    "        of the object are indexed. See `here\n",
    "        <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n",
    "        Applicable only to format='table'.\n",
    "    complevel : int, 0-9, default None\n",
    "        Specifies a compression level for data.\n",
    "        A value of 0 disables compression.\n",
    "    complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
    "        Specifies the compression library to be used.\n",
    "        As of v0.20.2 these additional compressors for Blosc are supported\n",
    "        (default if no compressor specified: 'blosc:blosclz'):\n",
    "        {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
    "        'blosc:zlib', 'blosc:zstd'}.\n",
    "        Specifying a compression library which is not available issues\n",
    "        a ValueError.\n",
    "    fletcher32 : bool, default False\n",
    "        If applying compression use the fletcher32 checksum\n",
    "    dropna : boolean, default False.\n",
    "        If true, ALL nan rows will not be written to store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del s\n",
    "del store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a DataFrame from a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_hdf(FILE, key='series')  # the `key` param can be omitted if the HDF file contains a single pandas object\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(FILE, key='df')  # the `key` param can be omitted if the HDF file contains a single pandas object\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm test.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/Write a compressed HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(10, size=(1000, 1000))\n",
    "df = pd.DataFrame(a)\n",
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(FILE, key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh test.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(FILE,\n",
    "          key='df',\n",
    "          complevel=9,     # 0-9, default None, Specifies a compression level for data. 0 = disables compression\n",
    "          complib='zlib') # 'zlib', 'lzo', 'bzip2', 'blosc', 'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy', 'blosc:zlib', 'blosc:zstd'. default 'zlib'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh test.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(FILE, key='df')  # the `key` param can be omitted if the HDF file contains a single pandas object\n",
    "df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm test.h5"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
